---
title: 病理预处理通用代码
published: 2024-08-01
description: ''
image: ''
tags: [病理,预处理]
category: '代码'
draft: false 
---

## 病理切片

使用方式:`python deepzoom_tiler.py -m 0 -b 20 -d [DATASET_NAME]`
 Set flag -m [LEVEL 1] [LEVEL 2] to crop patches from multiple magnifications.
```python
import json
from multiprocessing import Process, JoinableQueue
import argparse
import os
import re
import shutil
import sys
import glob
import numpy as np
import math
from unicodedata import normalize
from skimage import io
from skimage.color import rgb2hsv
from skimage.util import img_as_ubyte
from skimage import filters
from PIL import Image, ImageFilter, ImageStat

Image.MAX_IMAGE_PIXELS = None

import openslide
from openslide import open_slide, ImageSlide
from openslide.deepzoom import DeepZoomGenerator

VIEWER_SLIDE_NAME = 'slide'


class TileWorker(Process):
    """A child process that generates and writes tiles."""

    def __init__(self, queue, slidepath, tile_size, overlap, limit_bounds, quality, threshold):
        Process.__init__(self, name='TileWorker')
        self.daemon = True
        self._queue = queue
        self._slidepath = slidepath
        self._tile_size = tile_size
        self._overlap = overlap
        self._limit_bounds = limit_bounds
        self._quality = quality
        self._threshold = threshold
        self._slide = None

    def run(self):
        self._slide = open_slide(self._slidepath)
        last_associated = None
        dz = self._get_dz()
        while True:
            data = self._queue.get()
            if data is None:
                self._queue.task_done()
                break
            associated, level, address, outfile = data
            if last_associated != associated:
                dz = self._get_dz(associated)
                last_associated = associated
            try:
                tile = dz.get_tile(level, address)
                edge = tile.filter(ImageFilter.FIND_EDGES)
                edge = ImageStat.Stat(edge).sum
                edge = np.mean(edge) / (self._tile_size**2)
                w, h = tile.size
                if edge > self._threshold:
                    if not (w == self._tile_size and h == self._tile_size):
                        tile = tile.resize((self._tile_size, self._tile_size))
                    tile.save(outfile, quality=self._quality)
            except:
                pass
            self._queue.task_done()

    def _get_dz(self, associated=None):
        if associated is not None:
            image = ImageSlide(self._slide.associated_images[associated])
        else:
            image = self._slide
        return DeepZoomGenerator(
            image, self._tile_size, self._overlap, limit_bounds=self._limit_bounds
        )


class DeepZoomImageTiler(object):
    """Handles generation of tiles and metadata for a single image."""

    def __init__(self, dz, basename, target_levels, mag_base, format, associated, queue):
        self._dz = dz
        self._basename = basename
        self._format = format
        self._associated = associated
        self._queue = queue
        self._processed = 0
        self._target_levels = target_levels
        self._mag_base = int(mag_base)

    def run(self):
        self._write_tiles()

    def _write_tiles(self):
        target_levels = [self._dz.level_count - i - 1 for i in self._target_levels]
        mag_list = [int(self._mag_base / 2**i) for i in self._target_levels]
        mag_idx = 0
        for level in range(self._dz.level_count):
            if not (level in target_levels):
                continue
            tiledir = os.path.join("%s_files" % self._basename, str(mag_list[mag_idx]))
            if not os.path.exists(tiledir):
                os.makedirs(tiledir)
            cols, rows = self._dz.level_tiles[level]
            for row in range(rows):
                for col in range(cols):
                    tilename = os.path.join(tiledir, '%d_%d.%s' % (col, row, self._format))
                    if not os.path.exists(tilename):
                        self._queue.put((self._associated, level, (col, row), tilename))
                    self._tile_done()
            mag_idx += 1

    def _tile_done(self):
        self._processed += 1
        count, total = self._processed, self._dz.tile_count
        if count % 100 == 0 or count == total:
            print(
                "Tiling %s: wrote %d/%d tiles" % (self._associated or 'slide', count, total),
                end='\r',
                file=sys.stderr,
            )
            if count == total:
                print(file=sys.stderr)


class DeepZoomStaticTiler(object):
    """Handles generation of tiles and metadata for all images in a slide."""

    def __init__(
        self,
        slidepath,
        basename,
        mag_levels,
        base_mag,
        objective,
        format,
        tile_size,
        overlap,
        limit_bounds,
        quality,
        workers,
        threshold,
    ):
        self._slide = open_slide(slidepath)
        self._basename = basename
        self._format = format
        self._tile_size = tile_size
        self._overlap = overlap
        self._mag_levels = mag_levels
        self._base_mag = base_mag
        self._objective = objective
        self._limit_bounds = limit_bounds
        self._queue = JoinableQueue(2 * workers)
        self._workers = workers
        self._dzi_data = {}
        for _i in range(workers):
            TileWorker(
                self._queue, slidepath, tile_size, overlap, limit_bounds, quality, threshold
            ).start()

    def run(self):
        self._run_image()
        self._shutdown()

    def _run_image(self, associated=None):
        """Run a single image from self._slide."""
        if associated is None:
            image = self._slide
            basename = self._basename
        else:
            image = ImageSlide(self._slide.associated_images[associated])
            basename = os.path.join(self._basename, self._slugify(associated))
        dz = DeepZoomGenerator(
            image, self._tile_size, self._overlap, limit_bounds=self._limit_bounds
        )

        MAG_BASE = self._slide.properties.get(openslide.PROPERTY_NAME_OBJECTIVE_POWER)
        if MAG_BASE is None:
            MAG_BASE = self._objective
        first_level = int(
            math.log2(float(MAG_BASE) / self._base_mag)
        )  # raw / input, 40/20=2, 40/40=0
        target_levels = [i + first_level for i in self._mag_levels]  # levels start from 0
        target_levels.reverse()

        tiler = DeepZoomImageTiler(
            dz, basename, target_levels, MAG_BASE, self._format, associated, self._queue
        )
        tiler.run()

    def _url_for(self, associated):
        if associated is None:
            base = VIEWER_SLIDE_NAME
        else:
            base = self._slugify(associated)
        return '%s.dzi' % base

    def _copydir(self, src, dest):
        if not os.path.exists(dest):
            os.makedirs(dest)
        for name in os.listdir(src):
            srcpath = os.path.join(src, name)
            if os.path.isfile(srcpath):
                shutil.copy(srcpath, os.path.join(dest, name))

    @classmethod
    def _slugify(cls, text):
        text = normalize('NFKD', text.lower()).encode('ascii', 'ignore').decode()
        return re.sub('[^a-z0-9]+', '_', text)

    def _shutdown(self):
        for _i in range(self._workers):
            self._queue.put(None)
        self._queue.join()


def nested_patches(img_slide, out_base, level=(0,), ext='jpeg'):
    print('\n Organizing patches')
    img_name = img_slide.split(os.sep)[-1].split('.')[0]
    img_class = img_slide.split(os.sep)[2]
    n_levels = len(glob.glob('WSI_temp_files/*'))
    bag_path = os.path.join(out_base, img_class, img_name)
    os.makedirs(bag_path, exist_ok=True)
    if len(level) == 1:
        patches = glob.glob(os.path.join('WSI_temp_files', '*', '*.' + ext))
        for i, patch in enumerate(patches):
            patch_name = patch.split(os.sep)[-1]
            shutil.move(patch, os.path.join(bag_path, patch_name))
            sys.stdout.write('\r Patch [%d/%d]' % (i + 1, len(patches)))
        print('Done.')
    else:
        level_factor = 2 ** int(level[1] - level[0])
        levels = [int(os.path.basename(i)) for i in glob.glob(os.path.join('WSI_temp_files', '*'))]
        levels.sort()
        low_patches = glob.glob(os.path.join('WSI_temp_files', str(levels[0]), '*.' + ext))
        for i, low_patch in enumerate(low_patches):
            low_patch_name = low_patch.split(os.sep)[-1]
            shutil.move(low_patch, os.path.join(bag_path, low_patch_name))
            low_patch_folder = low_patch_name.split('.')[0]
            high_patch_path = os.path.join(bag_path, low_patch_folder)
            os.makedirs(high_patch_path, exist_ok=True)
            low_x = int(low_patch_folder.split('_')[0])
            low_y = int(low_patch_folder.split('_')[1])
            high_x_list = list(range(low_x * level_factor, (low_x + 1) * level_factor))
            high_y_list = list(range(low_y * level_factor, (low_y + 1) * level_factor))
            for x_pos in high_x_list:
                for y_pos in high_y_list:
                    high_patch = glob.glob(
                        os.path.join(
                            'WSI_temp_files', str(levels[1]), '{}_{}.'.format(x_pos, y_pos) + ext
                        )
                    )
                    if len(high_patch) != 0:
                        high_patch = high_patch[0]
                        shutil.move(
                            high_patch,
                            os.path.join(bag_path, low_patch_folder, high_patch.split(os.sep)[-1]),
                        )
            try:
                os.rmdir(os.path.join(bag_path, low_patch_folder))
                os.remove(low_patch)
            except:
                pass
            sys.stdout.write('\r Patch [%d/%d]' % (i + 1, len(low_patches)))
        print('Done.')


if __name__ == '__main__':
    Image.MAX_IMAGE_PIXELS = None
    parser = argparse.ArgumentParser(description='Patch extraction for WSI')
    parser.add_argument('-d', '--dataset', type=str, default='TCGA-lung', help='Dataset name')
    parser.add_argument(
        '-e', '--overlap', type=int, default=0, help='Overlap of adjacent tiles [0]'
    )
    parser.add_argument(
        '-f', '--format', type=str, default='jpeg', help='Image format for tiles [jpeg]'
    )
    parser.add_argument(
        '-v', '--slide_format', type=str, default='svs', help='Image format for tiles [svs]'
    )
    parser.add_argument(
        '-j', '--workers', type=int, default=20, help='Number of worker processes to start [20]'
    )
    parser.add_argument(
        '-q', '--quality', type=int, default=90, help='JPEG compression quality [90]'
    )
    parser.add_argument('-s', '--tile_size', type=int, default=224, help='Tile size [224]')
    parser.add_argument(
        '-b',
        '--base_mag',
        type=float,
        default=20,
        help='Maximum magnification for patch extraction [20]',
    )
    parser.add_argument(
        '-m',
        '--magnifications',
        type=int,
        nargs='+',
        default=(0,),
        help='Levels for patch extraction [0]',
    )
    parser.add_argument(
        '-o',
        '--objective',
        type=float,
        default=20,
        help='The default objective power if metadata does not present [20]',
    )
    parser.add_argument(
        '-t', '--background_t', type=int, default=30, help='Threshold for filtering background [15]'
    )
    args = parser.parse_args()
    levels = tuple(sorted(args.magnifications))
    assert len(levels) <= 2, 'Only 1 or 2 magnifications are supported!'
    path_base = os.path.join('WSI', args.dataset)
    if len(levels) == 2:
        out_base = os.path.join('WSI', args.dataset, 'pyramid')
    else:
        out_base = os.path.join('WSI', args.dataset, 'single')
    all_slides = glob.glob(os.path.join(path_base, '*/*.' + args.slide_format)) + glob.glob(
        os.path.join(path_base, '*/*/*.' + args.slide_format)
    )

    # pos-i_pos-j -> x, y
    for idx, c_slide in enumerate(all_slides):
        print('Process slide {}/{}'.format(idx + 1, len(all_slides)))
        DeepZoomStaticTiler(
            c_slide,
            'WSI_temp',
            levels,
            args.base_mag,
            args.objective,
            args.format,
            args.tile_size,
            args.overlap,
            True,
            args.quality,
            args.workers,
            args.background_t,
        ).run()
        nested_patches(c_slide, out_base, levels, ext=args.format)
        shutil.rmtree('WSI_temp_files')
    print('Patch extraction done for {} slides.'.format(len(all_slides)))
```

## WSI类型转换

### mrxs to svs

```python
from openslide import OpenSlide
import pyvips
import numpy as np
from math import ceil
import openslide
import os
import tifffile
import cv2
from tqdm import tqdm
import time
import glob
import copy
import multiprocessing

TILE_SIZE = 512

gfi = lambda img, ind: copy.deepcopy(img[ind[0] : ind[1], ind[2] : ind[3]])


def find_file(path, depth_down, depth_up=0, suffix='.xml'):
    ret = []
    for i in range(depth_up, depth_down):
        _path = os.path.join(path, '*/' * i + '*' + suffix)
        ret.extend(glob.glob(_path))
    ret.sort()
    return ret


def up_to16_manifi(hw):
    return int(ceil(hw[0] / TILE_SIZE) * TILE_SIZE), int(ceil(hw[1] / TILE_SIZE) * TILE_SIZE)


def gen_im(wsi, index):
    ind = 0
    while True:
        temp_img = gfi(wsi, index[ind])
        ind += 1
        yield temp_img


def get_name_from_path(file_path: str, ret_all: bool = False):
    dir, n = os.path.split(file_path)
    n, suffix = os.path.splitext(n)
    if ret_all:
        return dir, n, suffix
    return n


def gen_patches_index(ori_size, *, img_size=224, stride=224, keep_last_size=False):
    """
    这个函数用来按照输入的size和patch大小，生成每个patch所在原始的size上的位置

    keep_last_size：表示当size不能整除patch的size的时候，最后一个patch要不要保持输入的img_size

    返回：
        一个np数组，每个成员表示当前patch所在的x和y的起点和终点如：
            [[x_begin,x_end,y_begin,y_end],...]
    """
    height, width = ori_size[:2]
    index = []
    if height < img_size or width < img_size:
        print("input size is ({} {}), small than img_size:{}".format(height, width, img_size))
        return index

    for h in range(0, height + 1, stride):
        xe = h + img_size
        if h + img_size > height:
            xe = height
            h = xe - img_size if keep_last_size else h

        for w in range(0, width + 1, stride):
            ye = w + img_size
            if w + img_size > width:
                ye = width
                w = ye - img_size if keep_last_size else w
            index.append(np.array([h, xe, w, ye]))

            if ye == width:
                break
        if xe == height:
            break
    return index


def just_ff(path: str, *, file=False, floder=True, create_floder=False, info=True):
    """
    Check the input path status. Exist or not.

    Args:
        path (str): _description_
        file (bool, optional): _description_. Defaults to False.
        floder (bool, optional): _description_. Defaults to True.
        create_floder (bool, optional): _description_. Defaults to False.
        info (bool, optional): _description_. Defaults to True.

    Returns:
        _type_: _description_
    """
    if file:
        return os.path.isfile(path)
    elif floder:
        if os.path.exists(path):
            return True
        else:
            if create_floder:
                try:
                    os.makedirs(path)
                    if info:
                        print(r"Path '{}' does not exists, but created ！！".format(path))
                    return True
                except ValueError:
                    if info:
                        print(
                            r"Path '{}' does not exists, and the creation failed ！！".format(path)
                        )
                    pass
            else:
                if info:
                    print(r"Path '{}' does not exists！！".format(path))
                return False


def just_dir_of_file(file_path: str, create_floder: bool = True):
    """_summary_
    Check the dir of the input file. If donot exist, creat it!
    Args:
        file_path (_type_): _description_
        create_floder (bool, optional): _description_. Defaults to True.

    Returns:
        _type_: _description_
    """
    _dir = os.path.split(file_path)[0]
    return just_ff(_dir, create_floder=create_floder)


def split_path(root_path: str, input_path: str):
    path_split = os.sep
    while root_path[-1] == path_split:
        root_path = root_path[0 : len(root_path) - 1]
    ret_path = input_path[len(root_path) : len(input_path)]
    if len(ret_path) == 0:
        return ''
    while ret_path[0] == path_split:
        ret_path = ret_path[1 : len(ret_path)]
    return ret_path


def gen_pyramid_tiff(in_file, out_file, select_level=0):
    svs_desc = 'Aperio Image Library Fake\nABC |AppMag = {mag}|Filename = {filename}|MPP = {mpp}'
    label_desc = 'Aperio Image Library Fake\nlabel {W}x{H}'
    macro_desc = 'Aperio Image Library Fake\nmacro {W}x{H}'
    odata = openslide.open_slide(in_file)
    mpp = float(odata.properties['mirax.LAYER_0_LEVEL_0_SECTION.MICROMETER_PER_PIXEL_X'])
    mag = 40
    if mpp <= 0.3:
        mag = 20
        mpp = mpp * 2
    resolution = [10000 / mpp, 10000 / mpp]
    resolutionunit = 'CENTIMETER'

    if odata.properties.get('aperio.Filename') is not None:
        filename = odata.properties['aperio.Filename']
    else:
        filename = get_name_from_path(in_file)

    print(f"loading '{in_file}'")
    start = time.time()
    image_py = pyvips.Image.openslideload(in_file, level=select_level)
    image = np.array(image_py)[..., 0:3]
    print(f"finish loading '{in_file}'. costing time:{time.time()-start}")

    thumbnail_im = np.zeros([762, 762, 3], dtype=np.uint8)
    thumbnail_im = cv2.putText(
        thumbnail_im,
        'thumbnail',
        (thumbnail_im.shape[1] // 4, thumbnail_im.shape[0] // 2),
        cv2.FONT_HERSHEY_PLAIN,
        6,
        color=(255, 0, 0),
        thickness=3,
    )

    label_im = np.zeros([762, 762, 3], dtype=np.uint8)
    label_im = cv2.putText(
        label_im,
        'label',
        (label_im.shape[1] // 4, label_im.shape[0] // 2),
        cv2.FONT_HERSHEY_PLAIN,
        6,
        color=(0, 255, 0),
        thickness=3,
    )

    macro_im = np.zeros([762, 762, 3], dtype=np.uint8)
    macro_im = cv2.putText(
        macro_im,
        'macro',
        (macro_im.shape[1] // 4, macro_im.shape[0] // 2),
        cv2.FONT_HERSHEY_PLAIN,
        6,
        color=(0, 0, 255),
        thickness=3,
    )

    tile_hw = np.int64([TILE_SIZE, TILE_SIZE])
    width, height = image.shape[0:2]
    multi_hw = np.int64(
        [
            (width, height),
            (width // 2, height // 2),
            (width // 4, height // 4),
            (width // 8, height // 8),
            (width // 16, height // 16),
            (width // 32, height // 32),
            (width // 64, height // 64),
        ]
    )

    with tifffile.TiffWriter(out_file, bigtiff=True) as tif:
        thw = tile_hw.tolist()
        compressionargs = dict(outcolorspace='YCbCr')
        kwargs = dict(
            subifds=0,
            photometric='rgb',
            planarconfig='CONTIG',
            compression='JPEG',
            compressionargs=compressionargs,
            dtype=np.uint8,
            metadata=None,
        )

        for i, hw in enumerate(multi_hw):
            hw = up_to16_manifi(hw)
            temp_wsi = cv2.resize(image, (hw[1], hw[0]))
            new_x, new_y = up_to16_manifi(hw)
            new_wsi = np.ones((new_x, new_y, 3), dtype=np.uint8) * 255
            new_wsi[0 : hw[0], 0 : hw[1], :] = temp_wsi[..., 0:3]
            index = gen_patches_index((new_x, new_y), img_size=TILE_SIZE, stride=TILE_SIZE)
            gen = gen_im(new_wsi, index)

            if i == 0:
                desc = svs_desc.format(mag=mag, filename=filename, mpp=mpp)
                tif.write(
                    data=gen,
                    shape=(*hw, 3),
                    tile=thw[::-1],
                    resolutionunit=resolutionunit,
                    description=desc,
                    **kwargs,
                )
                _hw = up_to16_manifi(multi_hw[-2])
                thumbnail_im = cv2.resize(image, (_hw[1], _hw[0]))[..., 0:3]
                tif.write(data=thumbnail_im, description='', **kwargs)
            else:
                tif.write(
                    data=gen,
                    shape=(*hw, 3),
                    tile=thw[::-1],
                    resolutionunit=resolutionunit,
                    description='',
                    **kwargs,
                )
        _hw = up_to16_manifi(multi_hw[-2])
        macro_im = cv2.resize(image, (_hw[1], _hw[0]))[..., 0:3]
        tif.write(
            data=macro_im,
            subfiletype=9,
            description=macro_desc.format(W=macro_im.shape[1], H=macro_im.shape[0]),
            **kwargs,
        )


def process_wsi_file(w_name):
    t1 = time.perf_counter()
    patient_name = w_name.split(os.path.sep)[-2]
    wsi_name = get_name_from_path(w_name)
    diff_path = split_path(DATA_DIR, get_name_from_path(w_name, ret_all=True)[0])
    save_path = os.path.join(SAVE_DIR, diff_path, f'{wsi_name}.svs')
    if just_ff(save_path, file=True):
        return
    just_dir_of_file(save_path)
    gen_pyramid_tiff(w_name, save_path)
    print(f'{wsi_name}:', time.perf_counter() - t1)


if __name__ == "__main__":
    DATA_DIR = '../../data/LBM_Path/Path'
    SAVE_DIR = '../../data/SVS/Path'

    wsi_list = find_file(DATA_DIR, 1, suffix='.mrxs')

    with multiprocessing.Pool(processes=1) as pool:
        list(tqdm(pool.imap(process_wsi_file, wsi_list), total=len(wsi_list)))
```

### kfb to svs

[可以使用这个csdn中的代码进行运行](https://blog.csdn.net/qq_56550595/article/details/135594533),仅支持windows
```python
import os
import subprocess
from time import time
from concurrent.futures import ThreadPoolExecutor, as_completed

def process_file(exe_path, kfb_elem_path, svs_dest_path, level):
    command = f'{exe_path} {kfb_elem_path} {svs_dest_path} {level}'
    start_time = time()
    print(f'Processing {os.path.basename(kfb_elem_path)} ...')
    p = subprocess.Popen(command, shell=True)
    p.wait()
    elapsed_time = time() - start_time
    print(f'\nFinished {os.path.basename(kfb_elem_path)}, time: {elapsed_time:.2f}s ...')

def main():
    src_folder_name = 'F:\\CLAM_DATA\\radiotherapy'
    des_folder_name = 'F:\\CLAM_DATA\\Test_data'
    level = 9
    exe_path = r'F:\CLAM_DATA\kfb_to_svs_Tool\x86\KFbioConverter.exe'

    if not os.path.exists(exe_path):
        raise FileNotFoundError('Could not find convert library.')

    if int(level) < 2 or int(level) > 9:
        raise AttributeError('NOTE: 2 < [level] <= 9')

    pwd = os.popen('chdir').read().strip()
    full_path = os.path.join(pwd, src_folder_name)
    dest_path = os.path.join(pwd, des_folder_name)
    if not os.path.exists(full_path):
        raise FileNotFoundError(f'could not get into dir {src_folder_name}')
    if not os.path.exists(dest_path):
        os.makedirs(dest_path)

    kfb_list = os.popen(f'dir {full_path}').read().split('\n')
    kfb_list = [elem.split(' ')[-1] for elem in kfb_list if elem.endswith('kfb')]

    print(f'Found {len(kfb_list)} slides, transferring to svs format ...')

    # Use ThreadPoolExecutor to parallelize file processing
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = []
        for elem in kfb_list:
            kfb_elem_path = os.path.join(full_path, elem)
            svs_dest_path = os.path.join(dest_path, elem.replace('.kfb', '.svs'))
            futures.append(executor.submit(process_file, exe_path, kfb_elem_path, svs_dest_path, level))

        # Wait for all futures to complete
        for future in as_completed(futures):
            future.result()  # This will re-raise any exceptions caught during the execution

if __name__ == "__main__":
    main()
```
