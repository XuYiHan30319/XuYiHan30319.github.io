---
title: VAE
published: 2024-07-29
description: ''
image: ''
tags: [机器学习]
category: '论文阅读'
draft: false 
---

## 自编码器生成图像

变分自编码器(VAE)是一类常见的生成模型,在设计生成图像的程序面前,我们应该首先考虑模型的输入是什么,如果模型只有一个输入,那么模型应该只有一个确定的输出,这是没有意义的.因此模型应该要有输入用于区分不同的图片,哪怕只是012这种序号.

但是我们不仅希望不同的输入能区分不同的图片,我们还应该让相似输入的输出类似.比如1.5就应该和1/2相似.为了满足这样的性质,我们应该把模型建模为有意义的高维实数向量,可以看做图片的压缩编码,比如(170,1)表示170cm的帅哥

大部分的生成模型都是这种方式铎生成过程建模,所有的输入向量都来自一个标准正态分布,图像生成就是把图像的编码向量解码为一幅图像的过程.自编码器的构造十分巧妙,他首先把图片压缩为一个编码,再让另一个模型学习如何把编码解压缩为一个图片,最小化生成图片与原图片之间的误差.

![img](https://zhouyifan.net/2022/12/19/20221016-VAE/2.jpg)

最后的解码器就是我们需要的生成模型,只需要从标准正态分布里面采样z就可以生成图片了.可是，由于自编码器本身的限制，这种理想不一定能实现。

## 自编码器问题:过拟合

自编码器的压缩能力很强大,只要编码器和解码器足够复杂,所有训练集的图像都可以被压缩为非常短的编码,短到只要一个一维向量就可以描述所有训练集的图像了.当然,这样的话编码z就失去了语义信息.这是由模型过拟合导致的。如果仅使用自编码器本身的约束方式，而不加入其他正则化方法的话，一定会出现过拟合。

![img](https://zhouyifan.net/2022/12/19/20221016-VAE/4.jpg)

## VAE=>正则化的自编码器

VAE就是某种正则化方法的自编码器,他解决了上述的过拟合问题.使用的方法来自概率论的变分推理

VAE的想法是这样的：我们最终希望得到一个分布Z，或者说一条连续的直线。可是，编码器每次只能把图片编码成一个向量，也就是一个点。很多点是很难重建出一条连续的直线的。既然如此，我们可以把每张图片也编码成一个分布。多条直线，就可以比较容易地拼成我们想要的直线了。

总结就是,VAE本身是一个编码器-解码器结构的自编码器，只不过编码器的输出是一个分布，而解码器的输入是该分布的一个样本。另外，在损失函数中，除了要让重建图像和原图像更接近以外，还要让输出的分布和标准正态分布更加接近。

##### 然而，为了抑制自编码过程中的过拟合，VAE编码器的输出是一个正态分布，而不是一个具体的编码。同时，VAE的损失函数除了约束重建图像外，还约束了生成的分布。在这些改进下，VAE能够顺利地训练出一个解码器，以把来自正态分布的随机变量z画成一幅图像。
